# DAFU - Data Analytics Functional Utilities 

[![License: AGPL v3](https://img.shields.io/badge/License-AGPL%20v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.95%2B-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-In%20Development-orange.svg)](https://www.docker.com/)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-Planned-yellow.svg)](https://kubernetes.io/)

**DAFU** is a comprehensive fraud detection and e-commerce analytics platform designed for enterprise deployment. Currently in active development, it provides advanced machine learning-based fraud detection capabilities with a focus on anomaly detection and sequence analysis.

## üåü Platform Overview

DAFU is a fraud detection platform that combines multiple machine learning algorithms to provide comprehensive fraud detection and prevention solutions. The platform is built with modern technologies and follows enterprise best practices, with core ML capabilities fully implemented and enterprise features in development.

### Current Capabilities (Implemented)

- üß† **Advanced ML Algorithms**: Isolation Forest and LSTM/GRU sequence models fully implemented
- üì° **Stream Processing**: Real-time data stream processing with pre-trained models ![NEW](https://img.shields.io/badge/NEW!-brightgreen)
- üíæ **Model Persistence**: Save and load trained models for production deployment ![NEW](https://img.shields.io/badge/NEW!-brightgreen)
- üîÄ **Dual Prediction Modes**: Both batch and stream prediction capabilities ![NEW](https://img.shields.io/badge/NEW!-brightgreen)
- üß™üéì **Dual Learning Modes**: Both supervised and unsupervised learning approaches
- üìäüìà **Comprehensive Analysis**: 4-panel visualization with detailed performance metrics
- üöÄ **Production-Ready Core**: Complete fraud detection pipeline with evaluation
- üïµÔ∏è‚Äç‚ôÄÔ∏èüéØ **Flexible Detection**: Classic and risk-score based detection methods
- üßπ **Data Processing**: Automatic preprocessing with missing value handling


### Planned Capabilities ![ROADMAP](https://img.shields.io/badge/ROADMAP-blue)

- ‚ö° **Real-time API** : Sub-50ms fraud scoring endpoints for ultra-low latency decisioning.  
  Enables the system to detect fraud instantly in live payment flows, ensuring compliance with real-time financial transaction requirements.

- üîê **Enterprise Security** : OAuth2, JWT, RBAC implementation.  
  Adds enterprise-grade authentication, token-based access, and role-based authorization to secure deployments in regulated environments.

- ‚ò∏Ô∏è **Scalable Architecture** : Kubernetes deployment with auto-scaling.  
  Provides seamless horizontal scaling based on traffic load, supporting both small-scale PoCs and large enterprise production clusters.

- üìà **Advanced Monitoring** : Prometheus, Grafana, Jaeger integration.  
  Full observability with metrics collection, real-time dashboards, and distributed tracing for faster issue detection and resolution.

- üö¶ **High-throughput Processing** : 10,000+ TPS optimization.  
  Optimized to handle extremely high transaction volumes, scaling to 10,000+ transactions per second to meet the demands of major banks and payment providers.

## üìã Table of Contents

### üöÄ Getting Started
- [Quick Start](#-quick-start)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
  - [First-Time User Guide](#first-time-user-guide)
- [Supported Data Formats](#-supported-data-formats)
- [Use Cases and Scenarios](#-use-cases-and-scenarios)

### üèóÔ∏è Architecture & Components
- [High-Level Architecture](#-architecture)
- [Core Components](#core-components)
  - [Fraud Detection Service](#1-fraud-detection-service-fraud_detection)
  - [Feature Engineering Pipeline](#2-feature-engineering-pipeline)
  - [API Services](#3-api-services)
  - [Enterprise Infrastructure](#4-enterprise-infrastructure)

### ‚öôÔ∏è Configuration & Usage
- [Configuration and Customization](#-configuration-and-customization)
- [Performance and Scalability](#-performance-and-scalability)
- [Security and Compliance](#-security-and-compliance)

### üß™ Development & Testing
- [Testing and Quality Assurance](#-testing-and-quality-assurance)
- [Monitoring and Observability](#-monitoring-and-observability)
- [Deployment](#-deployment)
- [Contributing](#-contributing)

### üìö API & Documentation
- [API Documentation](#-api-documentation)
  - [Fraud Scoring API](#fraud-scoring-api)
  - [Model Management API](#model-management-api)

### üìä Project Status
- [Current Implementation Status](#-current-implementation-status)
- [Performance Metrics](#-current-performance-metrics)
- [Development Roadmap](#-development-roadmap)
- [Test Results](#-current-test-results)

### üÜò Support
- [Support and Community](#-support-and-community)
- [License](#-license)

---

## üèóÔ∏è Architecture

### High-Level Architecture

![High-Level Architecture](images/High-level-architecture.drawio.png)

## Core Components

### 1. Fraud Detection Service (`/fraud_detection/`)
The main fraud detection microservice with **end-to-end ML capabilities**, exposed via **FastAPI** for real-time and batch use cases.

- **Anomaly Detection**: [Isolation Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) for unsupervised fraud detection and anomaly scoring.  
- **Sequence Models**: [LSTM (Long Short-Term Memory)](https://en.wikipedia.org/wiki/Long_short-term_memory) and [GRU (Gated Recurrent Unit)](https://en.wikipedia.org/wiki/Gated_recurrent_unit) models for temporal/behavioral pattern recognition.  
- **Ensemble Methods**: [XGBoost](https://xgboost.readthedocs.io/en/stable/) and [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) for robust, tree-based predictions.  
- **Neural Networks**: [Deep learning models](https://www.tensorflow.org/guide/keras/sequential_model) (via TensorFlow/Keras) for complex nonlinear fraud patterns.  
- **Rules Engine**: Extensible **business rules** for configurable thresholds, velocity checks, and custom scoring strategies.

---

### 2. Feature Engineering Pipeline
A **modular preprocessing and feature extraction pipeline** designed for **real-time** and **offline** analytics.

- **Transaction Features**: Amount distributions, frequency of transactions, merchant category profiling.  
- **User Features**: Historical behavioral patterns, device fingerprints, account age/risk indicators.  
- **Network Features**: Graph-based entity relationships (shared IPs, merchants, accounts).  
- **Temporal Features**: Time-series analysis (sliding windows, session duration, peak-time anomalies).

---

### 3. API Services
Enterprise-grade **RESTful APIs** providing low-latency endpoints for **real-time scoring** and **large-scale data ingestion**.  
All APIs are implemented using [FastAPI](https://fastapi.tiangolo.com/), leveraging [OpenAPI/Swagger](https://swagger.io/specification/) for documentation and schema validation.

- **Fraud Scoring API**: Real-time fraud detection endpoint.  
  - Built on [FastAPI](https://fastapi.tiangolo.com/) for async performance.  
  - Supports **REST** and optionally **gRPC** for low-latency scenarios.  
  - Designed for **sub-50ms** response times with Redis caching.  

- **Batch Processing API**: Bulk scoring and data ingestion.  
  - Optimized for large datasets with [Dask](https://www.dask.org/) / [Apache Spark](https://spark.apache.org/) integration.  
  - Used for offline analysis, backfills, reporting, and model monitoring.  
  - Supports scheduled jobs (via [Apache Airflow](https://airflow.apache.org/)).  

- **Model Management API**: Centralized model lifecycle control.  
  - Provides endpoints for **deployment**, **versioning**, and **rollback** of fraud detection models.  
  - Integrates with object storage ([MinIO](https://min.io/) / [Amazon S3](https://aws.amazon.com/s3/)) for model registry.  
  - Secured with [OAuth2](https://oauth.net/2/) / [JWT](https://jwt.io/) for enterprise compliance.  


---

### 4. Enterprise Infrastructure
A **cloud-native, microservices-based foundation**, optimized for scalability and observability.

- **Containerization**: [Docker](https://www.docker.com/) multi-stage builds for lightweight, reproducible services ([Podman](https://docs.podman.io/en/latest/) is another option).  
- **Orchestration**: [Kubernetes](https://kubernetes.io/) with [Helm](https://helm.sh/) charts for deployment, scaling, and service discovery.  
- **Monitoring**: [Prometheus](https://prometheus.io/) (metrics), [Grafana](https://grafana.com/) (dashboards), [Jaeger](https://www.jaegertracing.io/) (distributed tracing).  
- **Security**: [OAuth2](https://oauth.net/2/) / [JWT](https://jwt.io/) authentication, **RBAC policies**, and API key management for multi-tenant enterprise compliance.


## üöÄ Quick Start

### Prerequisites

- **Python 3.8+** (Python 3.9+ recommended)
- **Docker/Podman** (for containerized deployment)
- **Git** (for cloning the repository)
- **8GB+ RAM** (for ML model training)
- **2GB+ free disk space** (for models and data)

**Optional (for production):**
- Kubernetes cluster
- Redis (for caching)
- PostgreSQL/ClickHouse (for data storage)

### Installation

#### Option 1: Local Development Setup (Recommended)

**Step 1: Clone and Setup Environment**

```bash
# Clone the repository
git clone https://github.com/MasterFabric/dafu.git
cd dafu

# Create virtual environment
python3 -m venv dafu_env
source dafu_env/bin/activate  # On Windows: dafu_env\Scripts\activate

# Expected output:
# (dafu_env) masterfabric@machine:dafu$ 
```

**Step 2: Install Dependencies**

```bash
# Navigate to fraud detection module
cd fraud_detection

# Install minimal dependencies (recommended for first-time users)
pip install -r requirements-minimal.txt

# Expected output:
# Collecting numpy>=1.21.0
#   Downloading numpy-1.24.3-cp39-cp39-macosx_10_9_x86_64.whl (20.1 MB)
#      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 20.1/20.1 MB 2.1 MB/s eta 0:00:00
# Collecting pandas>=1.3.0
#   Downloading pandas-1.5.3-cp39-cp39-macosx_10_9_x86_64.whl (11.3 MB)
#      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 11.3/11.3 MB 2.8 MB/s eta 0:00:00
# ...
# Successfully installed numpy-1.24.3 pandas-1.5.3 scikit-learn-1.3.0 ...
```

**Step 3: Verify Installation**

```bash
# Test the installation
python -c "from src.models.anomaly_detection import IsolationForestFraudDetector; print('‚úÖ Installation successful!')"

# Expected output:
# ‚úÖ Installation successful!
```

**Step 4: Run Interactive Demo**

```bash
# Run the comprehensive test suite
python test_anomaly_detection.py

# Expected terminal interaction:
# ========================================
# üöÄ DAFU Fraud Detection System - Interactive Demo
# ========================================
# 
# üìä Data Analysis Results:
# - Dataset shape: (1000, 8)
# - Missing values: 0
# - Fraud rate: 5.0%
# 
# üéØ Learning Mode Selection:
# 1. Supervised Learning (with fraud labels)
# 2. Unsupervised Learning (anomaly detection)
# 
# Please select learning mode (1 or 2): 1
# 
# ‚úÖ Selected: Supervised Learning
# 
# üîß Detection Method Selection:
# 1. Classic Detection (binary classification)
# 2. Risk Score Detection (custom thresholds)
# 
# Please select detection method (1 or 2): 1
# 
# ‚úÖ Selected: Classic Detection
# 
# üìà Training Models...
# - Training Isolation Forest with contamination=0.01
# - Training Isolation Forest with contamination=0.05
# - Training Isolation Forest with contamination=0.1
# 
# ‚úÖ Models trained successfully!
# 
# üìä Evaluation Results:
# - Accuracy: 94.2%
# - Precision: 89.1%
# - Recall: 87.3%
# - F1-Score: 88.2%
# 
# üìà Generating visualizations...
# ‚úÖ Analysis complete! Results saved to: fraud_detection_results/
```

#### Option 2: Docker Setup (Containerized)

**Step 1: Build Docker Image**

```bash
# Build the fraud detection service
cd fraud_detection
docker build -f deployment/Dockerfile -t dafu-fraud-detection .

# Expected output:
# Sending build context to Docker daemon  45.2MB
# Step 1/8 : FROM python:3.9-slim
#  ---> 2c4c8b8b8b8b
# Step 2/8 : WORKDIR /app
#  ---> Running in 1234567890ab
#  ---> 1234567890ab
# Step 3/8 : COPY requirements.txt .
#  ---> 1234567890ab
# Step 4/8 : RUN pip install --no-cache-dir -r requirements.txt
#  ---> Running in 1234567890ab
# Collecting numpy>=1.21.0
# ...
# Successfully built 1234567890ab
# Successfully tagged dafu-fraud-detection:latest
```

**Step 2: Run Container**

```bash
# Run the service with sample data
docker run -it --rm -v $(pwd)/sample_fraud_data.csv:/app/data.csv dafu-fraud-detection python test_anomaly_detection.py

# Expected output:
# ========================================
# üöÄ DAFU Fraud Detection System - Docker Demo
# ========================================
# 
# üìä Loading data from: /app/data.csv
# - Dataset shape: (1000, 8)
# - Fraud rate: 5.0%
# 
# üéØ Running unsupervised anomaly detection...
# ‚úÖ Analysis complete! Results saved to: /app/fraud_detection_results/
```

#### Option 3: Kubernetes Deployment (Production)

**Step 1: Deploy with Helm**

```bash
# Deploy using Helm (when API is ready)
cd fraud_detection/deployment
helm install dafu-fraud-detection ./helm-charts/ \
  --set image.tag=latest \
  --set replicas=3 \
  --set resources.requests.memory=512Mi

# Expected output:
# NAME: dafu-fraud-detection
# LAST DEPLOYED: Mon Jan 15 10:30:00 2024
# NAMESPACE: default
# STATUS: deployed
# REVISION: 1
# TEST SUITE: None
```

**Step 2: Verify Deployment**

```bash
# Check pod status
kubectl get pods -l app=dafu-fraud-detection

# Expected output:
# NAME                                READY   STATUS    RESTARTS   AGE
# dafu-fraud-detection-7d4b8c9f-abc   1/1     Running   0          2m
# dafu-fraud-detection-7d4b8c9f-def   1/1     Running   0          2m
# dafu-fraud-detection-7d4b8c9f-ghi   1/1     Running   0          2m
```

### First-Time User Guide

#### üéØ Quick Demo (5 minutes)

**1. Run the Interactive Test Suite**

```bash
cd fraud_detection
python test_anomaly_detection.py
```

**Expected Terminal Questions:**
```
üéØ Learning Mode Selection:
1. Supervised Learning (with fraud labels)
2. Unsupervised Learning (anomaly detection)

Please select learning mode (1 or 2): 
```

**2. Choose Detection Method**

```
üîß Detection Method Selection:
1. Classic Detection (binary classification)
2. Risk Score Detection (custom thresholds)

Please select detection method (1 or 2): 
```

**3. View Results**

After completion, you'll see:
```
üìä Evaluation Results:
- Accuracy: 94.2%
- Precision: 89.1%
- Recall: 87.3%
- F1-Score: 88.2%

üìà Generating visualizations...
‚úÖ Analysis complete! Results saved to: fraud_detection_results/
```

#### üîÑ Stream Processing Demo (NEW!)

**1. Train a Model First**

```bash
python test_sequence_models_interactive.py
```

**Expected Questions:**
```
üéØ Prediction Mode Selection:
1. Batch Prediction (train and evaluate)
2. Stream Prediction (use pre-trained model)

Please select prediction mode (1 or 2): 1

üéØ Learning Mode Selection:
1. Supervised Learning
2. Unsupervised Learning

Please select learning mode (1 or 2): 1

üéØ Model Selection:
Available models: ['LSTM', 'GRU', 'Both']
Please select models (comma-separated): LSTM,GRU
```

**2. Test Stream Processing**

```bash
# Run stream prediction with pre-trained model
python test_sequence_models_interactive.py
```

**Select Stream Mode:**
```
üéØ Prediction Mode Selection:
1. Batch Prediction (train and evaluate)
2. Stream Prediction (use pre-trained model)

Please select prediction mode (1 or 2): 2

üìÅ Model Package Selection:
Available models: ['my_fraud_model', 'production_model']
Please select model: my_fraud_model

‚úÖ Model loaded successfully!
üìä Processing stream data...
‚úÖ Stream processing complete! Results saved to: stream_results/
```

#### üê≥ Docker Quick Start

**1. One-Command Demo**

```bash
# Run complete demo in Docker
docker run -it --rm \
  -v $(pwd)/sample_fraud_data.csv:/app/data.csv \
  -v $(pwd)/results:/app/results \
  dafu-fraud-detection \
  python test_anomaly_detection.py
```

**Expected Output:**
```
üöÄ DAFU Fraud Detection System - Docker Demo
========================================

üìä Data Analysis Results:
- Dataset shape: (1000, 8)
- Missing values: 0
- Fraud rate: 5.0%

üéØ Running unsupervised anomaly detection...
‚úÖ Analysis complete! Results saved to: /app/results/
```

#### üîß Troubleshooting

**Common Issues and Solutions:**

**Issue 1: Import Error**
```bash
ModuleNotFoundError: No module named 'src.models.anomaly_detection'
```

**Solution:**
```bash
# Make sure you're in the fraud_detection directory
cd fraud_detection
python -c "from src.models.anomaly_detection import IsolationForestFraudDetector; print('‚úÖ Fixed!')"
```

**Issue 2: Memory Error**
```bash
MemoryError: Unable to allocate array
```

**Solution:**
```bash
# Use smaller dataset or reduce model complexity
export PYTHONHASHSEED=0
python test_anomaly_detection.py
```

**Issue 3: Docker Build Fails**
```bash
ERROR: failed to solve: failed to resolve source
```

**Solution:**
```bash
# Clean Docker cache and rebuild
docker system prune -f
docker build --no-cache -f deployment/Dockerfile -t dafu-fraud-detection .
```

#### üìä Expected Performance

**System Requirements:**
- **Minimum**: 4GB RAM, 2 CPU cores
- **Recommended**: 8GB RAM, 4 CPU cores
- **Production**: 16GB+ RAM, 8+ CPU cores

**Processing Times:**
- **Small dataset (1K records)**: 10-30 seconds
- **Medium dataset (10K records)**: 2-5 minutes
- **Large dataset (100K records)**: 10-20 minutes
- **Stream processing**: <1 second per record

**Memory Usage:**
- **Training**: 2-4GB RAM
- **Prediction**: 500MB-1GB RAM
- **Stream mode**: 200-500MB RAM

### Basic Usage

#### 1. Fraud Detection Service

```python
from fraud_detection.src.models.anomaly_detection import IsolationForestFraudDetector

# Initialize the detector
detector = IsolationForestFraudDetector(random_state=42)

# Load and analyze your data
detector.load_and_analyze_data('transaction_data.csv')

# Setup learning mode (supervised/unsupervised)
detector.setup_learning_mode()

# Choose detection method
# - Classic: Binary classification with contamination levels
# - Risk Score: Custom threshold-based detection

# Preprocess data
detector.preprocess_data()

# Train models
detector.train_models([0.01, 0.05, 0.1])  # Multiple contamination levels

# Evaluate and visualize
if detector.is_supervised:
    detector.evaluate_models()

detector.create_visualizations(save_plots=True)
detector.export_results('fraud_analysis_results')
```

#### 2. Run Interactive Test Suite

```bash
# Run comprehensive anomaly detection tests
cd fraud_detection
python test_anomaly_detection.py

# Run sequence model tests
python test_sequence_models_interactive.py
```

**Note**: Real-time API endpoints are currently in development. The core ML functionality is fully implemented and can be used through the Python classes directly.

#### 3. Sequence Model Analysis (NEW! Enhanced)

```python
from fraud_detection.src.models.sequence_models import SequenceFraudDetector

# Initialize sequence detector
sequence_detector = SequenceFraudDetector()

# Setup prediction mode (NEW!)
sequence_detector.setup_prediction_mode()
# Choose: 1. Batch Prediction or 2. Stream Prediction

# For Batch Prediction Mode
if sequence_detector.prediction_mode == 'batch':
    # Load and analyze data
    sequence_detector.load_and_analyze_data('user_sequences.csv')
    
    # Setup learning mode
    sequence_detector.setup_learning_mode()
    
    # Preprocess data
    sequence_detector.preprocess_data()
    
    # Train models
    sequence_detector.train_models(['LSTM', 'GRU'])
    
    # Save trained models (NEW!)
    sequence_detector.save_model_package('my_fraud_model')
    
    # Evaluate and export
    sequence_detector.evaluate_models()
    sequence_detector.export_results('batch_results')

# For Stream Prediction Mode (NEW!)
elif sequence_detector.prediction_mode == 'stream':
    # Load pre-trained model
    sequence_detector.load_model_package('my_fraud_model')
    
    # Load new stream data
    stream_data = pd.read_csv('new_stream_data.csv')
    
    # Preprocess stream data
    processed_stream = sequence_detector.preprocess_stream_data(stream_data)
    
    # Make predictions on stream
    predictions = sequence_detector.predict_stream(processed_stream)
    
    # Export stream results (NEW!)
    sequence_detector.export_stream_results(stream_data, predictions)
```

#### 4. Stream Prediction with Isolation Forest (NEW!)

```python
from fraud_detection.src.models.anomaly_detection import IsolationForestFraudDetector

# Initialize detector
detector = IsolationForestFraudDetector()

# Setup prediction mode (NEW!)
detector.setup_prediction_mode()
# Choose: 1. Batch Prediction or 2. Stream Prediction

# For Stream Prediction Mode
if detector.prediction_mode == 'stream':
    # Load pre-trained model
    detector.load_model_package('trained_fraud_model')
    
    # Load new stream data
    stream_data = pd.read_csv('new_transactions.csv')
    
    # Preprocess stream data
    processed_stream = detector.preprocess_stream_data(stream_data)
    
    # Make predictions on stream
    results = detector.predict_stream(processed_stream, contamination=0.1)
    
    # Export stream results (NEW!)
    detector.export_stream_results(stream_data, results)
```

## üìä Supported Data Formats

### Transaction Data
```csv
transaction_id,user_id,amount,merchant_id,timestamp,category,is_fraud
tx_001,user_123,150.00,merchant_456,2024-01-15 10:30:00,electronics,0
tx_002,user_124,2500.00,merchant_789,2024-01-15 11:45:00,jewelry,1
```

### User Behavior Data
```csv
user_id,timestamp,action_type,device_id,location,amount
user_123,2024-01-15 10:30:00,login,mobile_device_001,location_A,0
user_123,2024-01-15 10:31:00,purchase,mobile_device_001,location_A,150.00
```

### Time Series Data
```csv
timestamp,user_id,transaction_count,daily_amount,risk_score
2024-01-15,user_123,5,750.00,0.2
2024-01-16,user_123,8,1200.00,0.4
```

## üéØ Use Cases and Scenarios

### 1. Real-time E-commerce Fraud Detection

**Scenario**: Detect fraudulent transactions in real-time during checkout
**Solution**: Risk Score API with sub-50ms response time

```python
# Real-time scoring
response = requests.post('https://api.dafu.masterfabric.co/v1/score', json={
    'transaction_id': 'tx_123',
    'amount': 150.00,
    'user_id': 'user_456',
    'merchant_id': 'merchant_789',
    'device_fingerprint': 'fp_abc123',
    'ip_address': '192.168.1.1',
    'user_agent': 'Mozilla/5.0...'
})

fraud_score = response.json()['risk_score']
is_fraud = fraud_score > 0.7  # Custom threshold
```

### 2. Batch Fraud Analysis

**Scenario**: Analyze historical data for fraud patterns and model retraining
**Solution**: Batch Processing API with large-scale data handling

```python
# Batch analysis
batch_request = {
    'data_source': 's3://fraud-data/transactions_2024.csv',
    'analysis_type': 'comprehensive',
    'models': ['isolation_forest', 'lstm', 'xgboost'],
    'output_format': 'detailed_report'
}

response = requests.post('https://api.dafu.masterfabric.co/v1/batch/analyze', json=batch_request)
```

### 3. User Behavior Analysis

**Scenario**: Detect anomalous user behavior patterns over time
**Solution**: Sequence models with LSTM/GRU for temporal pattern recognition

```python
# User behavior analysis
from fraud_detection.src.models.sequence_models import UserBehaviorAnalyzer

analyzer = UserBehaviorAnalyzer()
analyzer.load_user_sequences('user_behavior_data.csv')

# Detect anomalies in user patterns
anomalies = analyzer.detect_behavioral_anomalies(
    sequence_length=30,
    threshold=0.8
)
```

### 4. Merchant Risk Assessment

**Scenario**: Evaluate merchant risk profiles for payment processing
**Solution**: Multi-model ensemble with business rules

```python
# Merchant risk assessment
from fraud_detection.src.rules_engine.rule_processor import MerchantRiskProcessor

processor = MerchantRiskProcessor()
merchant_risk = processor.assess_merchant_risk(
    merchant_id='merchant_123',
    transaction_history='merchant_transactions.csv',
    risk_factors=['chargeback_rate', 'transaction_patterns', 'location_anomalies']
)
```

### 5. Real-time Stream Processing (NEW!)

**Scenario**: Process incoming transactions in real-time using pre-trained models
**Solution**: Stream prediction mode with model persistence

```python
# Real-time stream processing
from fraud_detection.src.models.anomaly_detection import IsolationForestFraudDetector

detector = IsolationForestFraudDetector()
detector.setup_prediction_mode()
# Choose: 2. Stream Prediction

# Load pre-trained model
detector.load_model_package('production_fraud_model')

# Process incoming transactions
while True:
    # Get new transaction from stream
    new_transaction = get_next_transaction()
    
    # Preprocess and predict
    processed = detector.preprocess_stream_data(new_transaction)
    result = detector.predict_stream(processed, contamination=0.1)
    
    # Take action based on prediction
    if result['predictions'][0] == 1:
        block_transaction(new_transaction)
    else:
        approve_transaction(new_transaction)
```

### 6. Model Training and Deployment Pipeline (NEW!)

**Scenario**: Train models on historical data and deploy for production use
**Solution**: Batch training with model persistence

```python
# Training and deployment pipeline
from fraud_detection.src.models.sequence_models import SequenceFraudDetector

# Phase 1: Train models
trainer = SequenceFraudDetector()
trainer.setup_prediction_mode()
# Choose: 1. Batch Prediction

trainer.load_and_analyze_data('historical_fraud_data.csv')
trainer.setup_learning_mode()
trainer.preprocess_data()
trainer.train_models(['LSTM', 'GRU'])

# Save trained models for production
trainer.save_model_package('production_lstm_model')
print("‚úÖ Models trained and saved for production use")

# Phase 2: Deploy for stream processing
deployer = SequenceFraudDetector()
deployer.setup_prediction_mode()
# Choose: 2. Stream Prediction

deployer.load_model_package('production_lstm_model')
print("‚úÖ Models loaded and ready for stream processing")
```

### 7. Network Analysis and Graph-based Detection

**Scenario**: Detect fraud rings and coordinated attacks
**Solution**: Network features with graph analysis

```python
# Network fraud detection
from fraud_detection.src.feature_engineering.network_features import NetworkAnalyzer

analyzer = NetworkAnalyzer()
fraud_rings = analyzer.detect_fraud_networks(
    transaction_data='network_transactions.csv',
    similarity_threshold=0.8,
    min_ring_size=3
)
```

## üîß Configuration and Customization

### Environment Configuration

```bash
# .env file
DATABASE_URL=postgresql://user:password@localhost:5432/dafu
REDIS_URL=redis://localhost:6379/0
MODEL_STORAGE_PATH=/models
LOG_LEVEL=INFO
API_RATE_LIMIT=1000
FRAUD_THRESHOLD=0.7
```

### Model Configuration

```python
# config/models.json
{
    "isolation_forest": {
        "contamination": [0.01, 0.05, 0.1],
        "n_estimators": 100,
        "random_state": 42
    },
    "lstm": {
        "sequence_length": 10,
        "hidden_units": 64,
        "dropout": 0.2,
        "epochs": 50
    },
    "xgboost": {
        "n_estimators": 100,
        "max_depth": 6,
        "learning_rate": 0.1
    }
}
```

### Business Rules Configuration

```python
# config/rules.json
{
    "amount_threshold": {
        "condition": "amount > 10000",
        "risk_score": 0.8,
        "action": "flag_for_review"
    },
    "velocity_check": {
        "condition": "transactions_per_hour > 10",
        "risk_score": 0.6,
        "action": "additional_verification"
    },
    "location_anomaly": {
        "condition": "distance_from_home > 1000km",
        "risk_score": 0.5,
        "action": "location_verification"
    }
}
```

## üìà Performance and Scalability

### Performance Metrics

- **Latency**: <50ms for real-time scoring
- **Throughput**: 10,000+ transactions per second
- **Accuracy**: 95%+ fraud detection accuracy
- **Availability**: 99.9% uptime SLA

### Scaling Options

#### Horizontal Scaling
```yaml
# Kubernetes HPA configuration
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: dafu-fraud-detection
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: dafu-fraud-detection
  minReplicas: 3
  maxReplicas: 50
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

#### Caching Strategy
```python
# Redis caching for model predictions
import redis
from functools import wraps

redis_client = redis.Redis(host='localhost', port=6379, db=0)

def cache_prediction(expiration=3600):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            cache_key = f"prediction:{hash(str(args) + str(kwargs))}"
            cached_result = redis_client.get(cache_key)
            
            if cached_result:
                return json.loads(cached_result)
            
            result = func(*args, **kwargs)
            redis_client.setex(cache_key, expiration, json.dumps(result))
            return result
        return wrapper
    return decorator
```

## üîí Security and Compliance

### Security Features

- **Authentication**: OAuth2/JWT token-based authentication
- **Authorization**: Role-based access control (RBAC)
- **Data Encryption**: TLS 1.3 for data in transit, AES-256 for data at rest
- **Input Validation**: Comprehensive data validation and sanitization
- **Audit Logging**: Complete audit trail for compliance

### Compliance Standards

- **GDPR**: Data processing transparency and user rights
- **PCI DSS**: Secure payment card data handling
- **SOC 2**: Security controls and monitoring
- **ISO 27001**: Information security management

### Security Configuration

```python
# Security middleware
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware

app = FastAPI()

# CORS configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://dafu.masterfabric.co"],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)

# Trusted hosts
app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["dafu.masterfabric.co", "*.masterfabric.co"]
)
```

## üß™ Testing and Quality Assurance

### Test Suite

```bash
# Run all tests
cd fraud_detection
pytest tests/ -v --cov=src --cov-report=html

# Run specific test categories
pytest tests/test_anomaly_detection.py -v
pytest tests/test_api_endpoints.py -v
pytest tests/test_feature_engineering.py -v

# Performance testing
pytest tests/test_performance.py -v --benchmark-only
```

### Code Quality

```bash
# Linting and formatting
black src/ tests/
flake8 src/ tests/
mypy src/
pylint src/

# Pre-commit hooks
pre-commit install
pre-commit run --all-files
```

## üìä Monitoring and Observability

### Metrics Collection

```python
# Prometheus metrics
from prometheus_client import Counter, Histogram, Gauge

fraud_predictions_total = Counter('fraud_predictions_total', 'Total fraud predictions', ['model', 'result'])
prediction_latency = Histogram('prediction_latency_seconds', 'Prediction latency')
active_models = Gauge('active_models_total', 'Number of active models')
```

### Logging Configuration

```python
# Structured logging
import structlog

logger = structlog.get_logger()

# Usage
logger.info(
    "fraud_prediction_completed",
    transaction_id="tx_123",
    model="isolation_forest",
    risk_score=0.85,
    processing_time_ms=45
)
```

### Grafana Dashboards

- **Fraud Detection Metrics**: Prediction accuracy, latency, throughput
- **Model Performance**: Model accuracy, drift detection, retraining triggers
- **System Health**: CPU, memory, disk usage, API response times
- **Business Metrics**: Fraud rates, false positives, cost analysis

## üöÄ Deployment

### Production Deployment

#### Docker Compose (Development)
```yaml
# docker-compose.yml
version: '3.8'
services:
  fraud-detection:
    build: ./fraud_detection
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/dafu
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
  
  db:
    image: postgres:13
    environment:
      POSTGRES_DB: dafu
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
  
  redis:
    image: redis:6-alpine
  
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
  
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
```

#### Kubernetes Production
```bash
# Deploy to Kubernetes
kubectl apply -f fraud_detection/deployment/k8s-manifests/

# Or using Helm
helm install dafu ./fraud_detection/deployment/helm-charts/ \
  --set image.tag=latest \
  --set replicas=3 \
  --set resources.requests.memory=512Mi \
  --set resources.requests.cpu=250m
```

### CI/CD Pipeline

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production
on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Run tests
        run: |
          cd fraud_detection
          pip install -r requirements.txt
          pytest tests/
  
  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to Kubernetes
        run: |
          kubectl set image deployment/dafu-fraud-detection \
            fraud-detection=masterfabric/dafu:latest
```

## üìö API Documentation

### Fraud Scoring API

#### POST `/v1/score`
Real-time fraud scoring endpoint.

**Request:**
```json
{
  "transaction_id": "tx_123",
  "amount": 150.00,
  "user_id": "user_456",
  "merchant_id": "merchant_789",
  "timestamp": "2024-01-15T10:30:00Z",
  "device_fingerprint": "fp_abc123",
  "ip_address": "192.168.1.1"
}
```

**Response:**
```json
{
  "transaction_id": "tx_123",
  "risk_score": 0.85,
  "is_fraud": true,
  "model_used": "isolation_forest",
  "processing_time_ms": 45,
  "confidence": 0.92,
  "explanations": {
    "amount_risk": 0.3,
    "user_behavior_risk": 0.7,
    "merchant_risk": 0.2
  }
}
```

#### POST `/v1/batch/analyze`
Batch fraud analysis endpoint.

**Request:**
```json
{
  "data_source": "s3://bucket/data.csv",
  "analysis_type": "comprehensive",
  "models": ["isolation_forest", "lstm", "xgboost"],
  "output_format": "detailed_report"
}
```

### Model Management API

#### GET `/v1/models`
List available models.

#### POST `/v1/models/deploy`
Deploy a new model version.

#### GET `/v1/models/{model_id}/performance`
Get model performance metrics.

## ü§ù Contributing

### Development Setup

1. **Fork the repository**
2. **Create a feature branch**
   ```bash
   git checkout -b feature/your-feature-name
   ```
3. **Install development dependencies**
   ```bash
   cd fraud_detection
   pip install -r requirements.txt
   pip install -r requirements-dev.txt  # If available
   ```
4. **Run tests and linting**
   ```bash
   pytest tests/
   black src/ tests/
   flake8 src/ tests/
   ```
5. **Submit a pull request**

### Code Standards

- **Python Style**: PEP 8 compliance with Black formatting
- **Type Hints**: Comprehensive type annotations
- **Documentation**: Google-style docstrings
- **Testing**: 90%+ test coverage required
- **ASCII Only**: No non-ASCII characters in code (enforced by pre-commit hooks)

### Commit Convention

Follow the conventional commit format:
```
type(scope): description

[optional body]

[optional footer]
```

Types: `feat`, `fix`, `docs`, `style`, `refactor`, `test`, `chore`

## üìÑ License

This project is licensed under the **GNU Affero General Public License v3.0 (AGPL-3.0)**.

### License Summary

- **Commercial Use**: ‚úÖ Allowed with restrictions
- **Modification**: ‚úÖ Allowed
- **Distribution**: ‚úÖ Allowed with source code disclosure
- **Patent Use**: ‚úÖ Allowed
- **Private Use**: ‚úÖ Allowed
- **Sublicensing**: ‚ùå Not allowed

### Key Requirements

1. **Source Code Disclosure**: Any distribution of the software must include the complete source code
2. **Network Interaction**: If you run the software on a server and provide services over a network, you must make the source code available to users
3. **License Compatibility**: Any derivative works must be licensed under the same AGPL-3.0 license
4. **Attribution**: You must retain all copyright notices and license text

### Full License Text

The complete license text is available in the [LICENSE](LICENSE) file in this repository.

### Enterprise Licensing

For commercial enterprises requiring different licensing terms, please contact MasterFabric for enterprise licensing options.

**MasterFabric** - Enterprise-level fraud detection and e-commerce analytics solutions.

## üÜò Support and Community

### Getting Help

- **Documentation**: Comprehensive guides and API documentation
- **GitHub Issues**: Bug reports and feature requests
- **Community Forum**: Discussions and Q&A
- **Enterprise Support**: Contact the platform support team

### Resources

- **API Documentation**: [Swagger UI](https://api.dafu.masterfabric.co/docs)
- **Architecture Guide**: [docs/architecture.md](docs/architecture.md)
- **Deployment Guide**: [docs/deployment.md](docs/deployment.md)
- **Performance Tuning**: [docs/performance.md](docs/performance.md)

### Common Issues

1. **High Memory Usage**: Configure chunked processing for large datasets
2. **Slow Predictions**: Enable model caching and optimize feature engineering
3. **False Positives**: Adjust risk score thresholds and retrain models
4. **API Rate Limiting**: Configure appropriate rate limits for your use case

---

**DAFU Enterprise Fraud Detection Platform v1.0.0**  
*Built with ‚ù§Ô∏è for secure, scalable, and intelligent fraud detection*

---

## üèÜ Current Implementation Status

### ‚úÖ **Implemented Features (Production Ready)**

| Feature | Description | Status | Implementation Level |
|---------|-------------|--------|---------------------|
| **Isolation Forest Detection** | Core anomaly detection algorithm | ‚úÖ **Fully Implemented** | Complete with evaluation & visualization |
| **Sequence Models (LSTM/GRU)** | Time-series fraud detection | ‚úÖ **Fully Implemented** | Complete with TensorFlow implementation |
| **Stream Prediction Mode** | Real-time data stream processing | ‚úÖ **NEW! Fully Implemented** | Complete with model persistence |
| **Batch Prediction Mode** | Batch data processing | ‚úÖ **NEW! Fully Implemented** | Complete with training & prediction |
| **Model Persistence** | Save/load trained models | ‚úÖ **NEW! Fully Implemented** | Complete with .joblib & .h5 support |
| **Data Preprocessing** | Automatic data analysis & feature engineering | ‚úÖ **Fully Implemented** | Complete with missing value handling |
| **Supervised/Unsupervised Modes** | Dual learning approaches | ‚úÖ **Fully Implemented** | Complete with mode selection |
| **Risk Score Detection** | Custom threshold-based detection | ‚úÖ **Fully Implemented** | Complete with business interpretation |
| **Comprehensive Evaluation** | Performance metrics & visualization | ‚úÖ **Fully Implemented** | Complete with 4-panel analysis |
| **Enhanced Result Export** | CSV, JSON output with stream support | ‚úÖ **Enhanced** | Complete with stream & batch exports |
| **Docker Support** | Containerization | ‚úÖ **Fully Implemented** | Dockerfile with multi-stage build |

### üöß **Partially Implemented (In Development)**

| Feature | Description | Status | Implementation Level |
|---------|-------------|--------|---------------------|
| **API Endpoints** | REST API for real-time scoring | üöß **Basic Structure** | API files exist but need implementation |
| **Feature Engineering Pipeline** | Advanced feature extraction | üöß **Basic Structure** | Framework exists, needs implementation |
| **Rules Engine** | Business rule processing | üöß **Basic Structure** | Framework exists, needs implementation |
| **Kubernetes Manifests** | Production deployment configs | üöß **Basic Structure** | K8s files exist but need testing |
| **Ensemble Models** | XGBoost, Random Forest | üöß **Basic Structure** | Framework exists, needs implementation |

### üìã **Planned Features (Roadmap)**

| Feature | Description | Status | Target Timeline |
|---------|-------------|--------|----------------|
| **Real-time API** | Sub-50ms fraud scoring API | üìã **Planned** | In Development |
| **Enterprise Security** | OAuth2, JWT, RBAC | üìã **Planned** | In Development |
| **Monitoring & Observability** | Prometheus, Grafana, Jaeger | üìã **Planned** | In Development |
| **Auto-scaling** | Kubernetes HPA | üìã **Planned** | In Development |
| **Advanced Analytics** | Graph-based fraud detection | üìã **Planned** | In Development |
| **Model Management** | Versioning, A/B testing | üìã **Planned** | In Development |
| **Compliance Features** | GDPR, PCI DSS compliance | üìã **Planned** | In Development |
| **High-throughput Processing** | 10,000+ TPS optimization | üìã **Planned** | In Development |

## üéØ Current Performance Metrics

### **Achieved Metrics**
- **Accuracy**: 90%+ fraud detection accuracy (based on test results)
- **Model Training**: Complete end-to-end pipeline
- **Data Processing**: Handles large datasets efficiently
- **Visualization**: Comprehensive 4-panel analysis plots
- **Export Capability**: Structured results with timestamps

### **Target Metrics (Roadmap)**
- **Latency**: <50ms for real-time scoring (planned)
- **Throughput**: 10,000+ transactions per second (planned)
- **Availability**: 99.9% uptime SLA (planned)
- **Security**: Zero data breaches (planned)

---

## üó∫Ô∏è Development Roadmap

### **Phase 1 - API & Security Foundation**
- [ ] **Real-time API Implementation**: Complete FastAPI endpoints for fraud scoring
- [ ] **Authentication & Authorization**: OAuth2/JWT implementation
- [ ] **Input Validation**: Comprehensive request validation
- [ ] **API Documentation**: OpenAPI/Swagger documentation
- [ ] **Basic Security**: HTTPS, CORS, rate limiting

### **Phase 2 - Enterprise Infrastructure**
- [ ] **Kubernetes Production Deployment**: Full K8s manifests and Helm charts
- [ ] **Monitoring & Observability**: Prometheus, Grafana, Jaeger integration
- [ ] **Auto-scaling**: Kubernetes HPA with custom metrics
- [ ] **Message Queuing**: RabbitMQ/Celery for async processing
- [ ] **Advanced Feature Engineering**: Complete pipeline implementation

### **Phase 3 - Advanced Features**
- [ ] **Model Management**: Versioning, A/B testing, model registry
- [ ] **Ensemble Methods**: XGBoost, Random Forest implementation
- [ ] **Graph-based Detection**: Network analysis for fraud rings
- [ ] **Business Rules Engine**: Complete rule processing system
- [ ] **Advanced Analytics**: Dashboard and reporting system

### **Phase 4 - Scale & Optimization**
- [ ] **High-throughput Optimization**: 10,000+ TPS processing
- [ ] **Performance Tuning**: Memory optimization, caching strategies
- [ ] **Compliance Features**: GDPR, PCI DSS compliance tools
- [ ] **Machine Learning Pipeline**: Automated model training and deployment
- [ ] **Multi-tenant Architecture**: Enterprise multi-tenancy support

---

## üìä Current Test Results

Based on the existing test results in the project:

### **Anomaly Detection Performance**
- **Accuracy**: 90%+ on test datasets
- **Detection Methods**: Both classic and risk-score based detection working
- **Contamination Levels**: Multiple levels (0.01, 0.05, 0.1) tested successfully
- **Visualization**: 4-panel analysis plots generated successfully
- **Stream Processing**: 100,000 records processed successfully (NEW!)

### **Sequence Model Performance (NEW! Enhanced)**
- **LSTM/GRU Models**: Successfully trained and evaluated
- **Time-series Analysis**: User behavior patterns detected
- **Model Architecture**: Configurable sequence length and hidden units
- **Training**: TensorFlow-based implementation with early stopping
- **Stream Prediction**: 10,000 sequence records processed in stream mode (NEW!)
- **Model Persistence**: Models saved and loaded successfully (NEW!)

### **Stream Processing Capabilities (NEW!)**
- **Real-time Processing**: Stream data processed with pre-trained models
- **Model Loading**: Pre-trained models loaded successfully for prediction
- **Data Preprocessing**: Stream data preprocessed using saved transformers
- **Prediction Accuracy**: High accuracy maintained in stream mode
- **Export Capabilities**: Stream results exported with timestamps

### **Data Processing Capabilities**
- **Automatic Analysis**: Column detection and data suitability assessment
- **Preprocessing**: Missing value handling, categorical encoding, scaling
- **Export Formats**: CSV and JSON outputs with timestamps
- **Large Datasets**: Efficient processing of substantial data volumes
- **Batch vs Stream**: Both processing modes working efficiently (NEW!)
